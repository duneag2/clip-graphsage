{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f61088b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install ftfy regex\n",
    "# !pip install git+https://github.com/openai/CLIP.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61317958",
   "metadata": {},
   "outputs": [],
   "source": [
    "## reproducibility를 위해 random seed 고정\n",
    "import torch\n",
    "import random\n",
    "import torch.backends.cudnn as cudnn\n",
    "import numpy as np\n",
    "\n",
    "torch.manual_seed(256)\n",
    "torch.cuda.manual_seed(256)\n",
    "torch.cuda.manual_seed_all(256)\n",
    "np.random.seed(0)\n",
    "cudnn.benchmark = False\n",
    "cudnn.deterministic = True\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6893a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import clip\n",
    "import torch\n",
    "from torchvision import datasets\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ca93d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset = [datasets.CIFAR10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77e6b13f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 6250/6250 [01:50<00:00, 56.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.1821   0.0773  -0.269   ...  1.104   -0.1808  -0.274  ]\n",
      " [ 0.04443  0.0546  -0.12366 ...  0.951    0.10187  0.1378 ]\n",
      " [ 0.3115  -0.06003 -0.3264  ...  0.5947  -0.1338   0.0629 ]\n",
      " ...\n",
      " [ 0.2439   0.03134 -0.2125  ...  0.5327  -0.01223 -0.01997]\n",
      " [ 0.3125   0.2238  -0.1232  ...  1.244    0.2986   0.02827]\n",
      " [ 0.04782  0.203   -0.2725  ...  0.3862   0.00713  0.1323 ]]\n",
      "[6 9 9 ... 9 1 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 1250/1250 [00:21<00:00, 57.51it/s]\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 94.990\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/koreagen/koreagen/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   43.7s finished\n",
      "/tmp/ipykernel_2362725/579803564.py:50: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  accuracy = np.mean((test_labels == predictions).astype(np.float)) * 100.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import clip\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load the model\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model, preprocess = clip.load('ViT-B/32', device)\n",
    "ACC_2 = []\n",
    "\n",
    "def get_features(dataset):\n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(DataLoader(dataset, batch_size=8)):\n",
    "            features = model.encode_image(images.to(device))\n",
    "\n",
    "            all_features.append(features)\n",
    "            all_labels.append(labels)\n",
    "\n",
    "    return torch.cat(all_features).cpu().numpy(), torch.cat(all_labels).cpu().numpy()\n",
    "\n",
    "# Load the dataset\n",
    "root = os.path.expanduser(\"~/.data\")\n",
    "for _ in Dataset:\n",
    "  try:\n",
    "    train = _(root, download=True, train=True, transform=preprocess)\n",
    "    test = _(root, download=True, train=False, transform=preprocess)\n",
    "  except:\n",
    "    train = _(root, download=True, split='train', transform=preprocess)\n",
    "    test = _(root, download=True, split='test', transform=preprocess)\n",
    "\n",
    "  # Calculate the image features\n",
    "  train_features, train_labels = get_features(train)\n",
    "  print(train_features)\n",
    "  print(train_labels)\n",
    "  test_features, test_labels = get_features(test)\n",
    "\n",
    "  # Perform logistic regression\n",
    "  classifier = LogisticRegression(random_state=0, C=0.316, max_iter=1000, verbose=1)\n",
    "  classifier.fit(train_features, train_labels)\n",
    "\n",
    "  # Evaluate using the logistic regression classifier\n",
    "  predictions = classifier.predict(test_features)\n",
    "  accuracy = np.mean((test_labels == predictions).astype(np.float)) * 100.\n",
    "  ACC_2.append(f'{train.__class__.__name__} : {accuracy}')\n",
    "  print(f\"Accuracy = {accuracy:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "dd676d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2437c56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "82c037c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>502</th>\n",
       "      <th>503</th>\n",
       "      <th>504</th>\n",
       "      <th>505</th>\n",
       "      <th>506</th>\n",
       "      <th>507</th>\n",
       "      <th>508</th>\n",
       "      <th>509</th>\n",
       "      <th>510</th>\n",
       "      <th>511</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.182129</td>\n",
       "      <td>0.077271</td>\n",
       "      <td>-0.269043</td>\n",
       "      <td>-0.252197</td>\n",
       "      <td>0.340820</td>\n",
       "      <td>-0.206543</td>\n",
       "      <td>-0.022476</td>\n",
       "      <td>0.421875</td>\n",
       "      <td>-0.105896</td>\n",
       "      <td>0.204956</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.348633</td>\n",
       "      <td>0.313965</td>\n",
       "      <td>0.542969</td>\n",
       "      <td>-0.122986</td>\n",
       "      <td>0.279785</td>\n",
       "      <td>0.118042</td>\n",
       "      <td>0.339600</td>\n",
       "      <td>1.103516</td>\n",
       "      <td>-0.180786</td>\n",
       "      <td>-0.273926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.044434</td>\n",
       "      <td>0.054596</td>\n",
       "      <td>-0.123657</td>\n",
       "      <td>-0.042114</td>\n",
       "      <td>0.639648</td>\n",
       "      <td>0.252686</td>\n",
       "      <td>0.126221</td>\n",
       "      <td>0.460693</td>\n",
       "      <td>-0.091492</td>\n",
       "      <td>0.153687</td>\n",
       "      <td>...</td>\n",
       "      <td>0.209473</td>\n",
       "      <td>0.604492</td>\n",
       "      <td>-0.056641</td>\n",
       "      <td>-0.043518</td>\n",
       "      <td>0.264893</td>\n",
       "      <td>0.195557</td>\n",
       "      <td>0.008942</td>\n",
       "      <td>0.951172</td>\n",
       "      <td>0.101868</td>\n",
       "      <td>0.137817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.311523</td>\n",
       "      <td>-0.060028</td>\n",
       "      <td>-0.326416</td>\n",
       "      <td>0.091553</td>\n",
       "      <td>0.375732</td>\n",
       "      <td>-0.092041</td>\n",
       "      <td>0.256348</td>\n",
       "      <td>0.528809</td>\n",
       "      <td>-0.168701</td>\n",
       "      <td>0.213379</td>\n",
       "      <td>...</td>\n",
       "      <td>0.182617</td>\n",
       "      <td>0.120544</td>\n",
       "      <td>0.006985</td>\n",
       "      <td>-0.364014</td>\n",
       "      <td>0.167480</td>\n",
       "      <td>0.406738</td>\n",
       "      <td>0.063354</td>\n",
       "      <td>0.594727</td>\n",
       "      <td>-0.133789</td>\n",
       "      <td>0.062927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.075439</td>\n",
       "      <td>-0.199829</td>\n",
       "      <td>-0.111267</td>\n",
       "      <td>0.022995</td>\n",
       "      <td>0.520508</td>\n",
       "      <td>0.013527</td>\n",
       "      <td>0.333008</td>\n",
       "      <td>0.644531</td>\n",
       "      <td>-0.185059</td>\n",
       "      <td>0.332031</td>\n",
       "      <td>...</td>\n",
       "      <td>0.040955</td>\n",
       "      <td>-0.085754</td>\n",
       "      <td>0.267578</td>\n",
       "      <td>-0.140869</td>\n",
       "      <td>0.055328</td>\n",
       "      <td>0.227295</td>\n",
       "      <td>0.216309</td>\n",
       "      <td>0.521973</td>\n",
       "      <td>0.082581</td>\n",
       "      <td>0.078857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.144287</td>\n",
       "      <td>0.273682</td>\n",
       "      <td>-0.015129</td>\n",
       "      <td>0.013245</td>\n",
       "      <td>-0.019623</td>\n",
       "      <td>0.052643</td>\n",
       "      <td>0.367676</td>\n",
       "      <td>0.298828</td>\n",
       "      <td>0.063599</td>\n",
       "      <td>-0.234131</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.232788</td>\n",
       "      <td>0.072144</td>\n",
       "      <td>0.181152</td>\n",
       "      <td>-0.333008</td>\n",
       "      <td>0.103577</td>\n",
       "      <td>0.120300</td>\n",
       "      <td>0.172729</td>\n",
       "      <td>0.808594</td>\n",
       "      <td>-0.005161</td>\n",
       "      <td>0.482422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>0.384521</td>\n",
       "      <td>0.001780</td>\n",
       "      <td>0.010330</td>\n",
       "      <td>-0.373535</td>\n",
       "      <td>0.003527</td>\n",
       "      <td>-0.173828</td>\n",
       "      <td>0.265137</td>\n",
       "      <td>0.809570</td>\n",
       "      <td>-0.310791</td>\n",
       "      <td>0.321533</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010033</td>\n",
       "      <td>0.174927</td>\n",
       "      <td>0.914551</td>\n",
       "      <td>-0.247437</td>\n",
       "      <td>0.102600</td>\n",
       "      <td>0.454102</td>\n",
       "      <td>0.049683</td>\n",
       "      <td>0.587891</td>\n",
       "      <td>0.343506</td>\n",
       "      <td>-0.193848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>0.326660</td>\n",
       "      <td>-0.057800</td>\n",
       "      <td>-0.433838</td>\n",
       "      <td>0.026611</td>\n",
       "      <td>0.405273</td>\n",
       "      <td>-0.307129</td>\n",
       "      <td>0.231445</td>\n",
       "      <td>0.496826</td>\n",
       "      <td>-0.186401</td>\n",
       "      <td>0.021179</td>\n",
       "      <td>...</td>\n",
       "      <td>0.096069</td>\n",
       "      <td>0.017242</td>\n",
       "      <td>0.181396</td>\n",
       "      <td>-0.292480</td>\n",
       "      <td>0.116516</td>\n",
       "      <td>0.266357</td>\n",
       "      <td>-0.109070</td>\n",
       "      <td>1.097656</td>\n",
       "      <td>0.289062</td>\n",
       "      <td>0.182129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>0.243896</td>\n",
       "      <td>0.031342</td>\n",
       "      <td>-0.212524</td>\n",
       "      <td>-0.059174</td>\n",
       "      <td>0.381104</td>\n",
       "      <td>0.453125</td>\n",
       "      <td>0.387207</td>\n",
       "      <td>0.718262</td>\n",
       "      <td>-0.110718</td>\n",
       "      <td>0.239990</td>\n",
       "      <td>...</td>\n",
       "      <td>0.255127</td>\n",
       "      <td>0.346436</td>\n",
       "      <td>0.281494</td>\n",
       "      <td>0.340820</td>\n",
       "      <td>0.271729</td>\n",
       "      <td>0.133545</td>\n",
       "      <td>-0.217529</td>\n",
       "      <td>0.532715</td>\n",
       "      <td>-0.012230</td>\n",
       "      <td>-0.019974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.223755</td>\n",
       "      <td>-0.123230</td>\n",
       "      <td>-0.211792</td>\n",
       "      <td>-0.057159</td>\n",
       "      <td>0.066162</td>\n",
       "      <td>0.348145</td>\n",
       "      <td>0.208618</td>\n",
       "      <td>-0.187622</td>\n",
       "      <td>-0.088989</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.075317</td>\n",
       "      <td>0.137817</td>\n",
       "      <td>0.528809</td>\n",
       "      <td>0.020004</td>\n",
       "      <td>0.259521</td>\n",
       "      <td>0.089355</td>\n",
       "      <td>-0.134033</td>\n",
       "      <td>1.244141</td>\n",
       "      <td>0.298584</td>\n",
       "      <td>0.028275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>0.047821</td>\n",
       "      <td>0.203003</td>\n",
       "      <td>-0.272461</td>\n",
       "      <td>0.181396</td>\n",
       "      <td>0.468018</td>\n",
       "      <td>-0.081421</td>\n",
       "      <td>0.358398</td>\n",
       "      <td>0.552734</td>\n",
       "      <td>0.261963</td>\n",
       "      <td>-0.092712</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.328857</td>\n",
       "      <td>0.116089</td>\n",
       "      <td>0.173706</td>\n",
       "      <td>-0.247437</td>\n",
       "      <td>0.064453</td>\n",
       "      <td>0.073853</td>\n",
       "      <td>0.348633</td>\n",
       "      <td>0.386230</td>\n",
       "      <td>0.007130</td>\n",
       "      <td>0.132324</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 512 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6    \\\n",
       "0     -0.182129  0.077271 -0.269043 -0.252197  0.340820 -0.206543 -0.022476   \n",
       "1      0.044434  0.054596 -0.123657 -0.042114  0.639648  0.252686  0.126221   \n",
       "2      0.311523 -0.060028 -0.326416  0.091553  0.375732 -0.092041  0.256348   \n",
       "3      0.075439 -0.199829 -0.111267  0.022995  0.520508  0.013527  0.333008   \n",
       "4      0.144287  0.273682 -0.015129  0.013245 -0.019623  0.052643  0.367676   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "49995  0.384521  0.001780  0.010330 -0.373535  0.003527 -0.173828  0.265137   \n",
       "49996  0.326660 -0.057800 -0.433838  0.026611  0.405273 -0.307129  0.231445   \n",
       "49997  0.243896  0.031342 -0.212524 -0.059174  0.381104  0.453125  0.387207   \n",
       "49998  0.312500  0.223755 -0.123230 -0.211792 -0.057159  0.066162  0.348145   \n",
       "49999  0.047821  0.203003 -0.272461  0.181396  0.468018 -0.081421  0.358398   \n",
       "\n",
       "            7         8         9    ...       502       503       504  \\\n",
       "0      0.421875 -0.105896  0.204956  ... -0.348633  0.313965  0.542969   \n",
       "1      0.460693 -0.091492  0.153687  ...  0.209473  0.604492 -0.056641   \n",
       "2      0.528809 -0.168701  0.213379  ...  0.182617  0.120544  0.006985   \n",
       "3      0.644531 -0.185059  0.332031  ...  0.040955 -0.085754  0.267578   \n",
       "4      0.298828  0.063599 -0.234131  ... -0.232788  0.072144  0.181152   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "49995  0.809570 -0.310791  0.321533  ...  0.010033  0.174927  0.914551   \n",
       "49996  0.496826 -0.186401  0.021179  ...  0.096069  0.017242  0.181396   \n",
       "49997  0.718262 -0.110718  0.239990  ...  0.255127  0.346436  0.281494   \n",
       "49998  0.208618 -0.187622 -0.088989  ... -0.075317  0.137817  0.528809   \n",
       "49999  0.552734  0.261963 -0.092712  ... -0.328857  0.116089  0.173706   \n",
       "\n",
       "            505       506       507       508       509       510       511  \n",
       "0     -0.122986  0.279785  0.118042  0.339600  1.103516 -0.180786 -0.273926  \n",
       "1     -0.043518  0.264893  0.195557  0.008942  0.951172  0.101868  0.137817  \n",
       "2     -0.364014  0.167480  0.406738  0.063354  0.594727 -0.133789  0.062927  \n",
       "3     -0.140869  0.055328  0.227295  0.216309  0.521973  0.082581  0.078857  \n",
       "4     -0.333008  0.103577  0.120300  0.172729  0.808594 -0.005161  0.482422  \n",
       "...         ...       ...       ...       ...       ...       ...       ...  \n",
       "49995 -0.247437  0.102600  0.454102  0.049683  0.587891  0.343506 -0.193848  \n",
       "49996 -0.292480  0.116516  0.266357 -0.109070  1.097656  0.289062  0.182129  \n",
       "49997  0.340820  0.271729  0.133545 -0.217529  0.532715 -0.012230 -0.019974  \n",
       "49998  0.020004  0.259521  0.089355 -0.134033  1.244141  0.298584  0.028275  \n",
       "49999 -0.247437  0.064453  0.073853  0.348633  0.386230  0.007130  0.132324  \n",
       "\n",
       "[50000 rows x 512 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d9fa8fa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████| 50000/50000 [00:00<00:00, 168857.03it/s]\n"
     ]
    }
   ],
   "source": [
    "val = []\n",
    "for i in tqdm(range(len(train_features))):\n",
    "    val.append(int(np.sum(train_features[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e3d5edfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "31a1e740",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'] = train_labels\n",
    "df['sum'] = val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "28aaaa5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>504</th>\n",
       "      <th>505</th>\n",
       "      <th>506</th>\n",
       "      <th>507</th>\n",
       "      <th>508</th>\n",
       "      <th>509</th>\n",
       "      <th>510</th>\n",
       "      <th>511</th>\n",
       "      <th>label</th>\n",
       "      <th>sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.182129</td>\n",
       "      <td>0.077271</td>\n",
       "      <td>-0.269043</td>\n",
       "      <td>-0.252197</td>\n",
       "      <td>0.340820</td>\n",
       "      <td>-0.206543</td>\n",
       "      <td>-0.022476</td>\n",
       "      <td>0.421875</td>\n",
       "      <td>-0.105896</td>\n",
       "      <td>0.204956</td>\n",
       "      <td>...</td>\n",
       "      <td>0.542969</td>\n",
       "      <td>-0.122986</td>\n",
       "      <td>0.279785</td>\n",
       "      <td>0.118042</td>\n",
       "      <td>0.339600</td>\n",
       "      <td>1.103516</td>\n",
       "      <td>-0.180786</td>\n",
       "      <td>-0.273926</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.044434</td>\n",
       "      <td>0.054596</td>\n",
       "      <td>-0.123657</td>\n",
       "      <td>-0.042114</td>\n",
       "      <td>0.639648</td>\n",
       "      <td>0.252686</td>\n",
       "      <td>0.126221</td>\n",
       "      <td>0.460693</td>\n",
       "      <td>-0.091492</td>\n",
       "      <td>0.153687</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.056641</td>\n",
       "      <td>-0.043518</td>\n",
       "      <td>0.264893</td>\n",
       "      <td>0.195557</td>\n",
       "      <td>0.008942</td>\n",
       "      <td>0.951172</td>\n",
       "      <td>0.101868</td>\n",
       "      <td>0.137817</td>\n",
       "      <td>9</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.311523</td>\n",
       "      <td>-0.060028</td>\n",
       "      <td>-0.326416</td>\n",
       "      <td>0.091553</td>\n",
       "      <td>0.375732</td>\n",
       "      <td>-0.092041</td>\n",
       "      <td>0.256348</td>\n",
       "      <td>0.528809</td>\n",
       "      <td>-0.168701</td>\n",
       "      <td>0.213379</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006985</td>\n",
       "      <td>-0.364014</td>\n",
       "      <td>0.167480</td>\n",
       "      <td>0.406738</td>\n",
       "      <td>0.063354</td>\n",
       "      <td>0.594727</td>\n",
       "      <td>-0.133789</td>\n",
       "      <td>0.062927</td>\n",
       "      <td>9</td>\n",
       "      <td>-6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.075439</td>\n",
       "      <td>-0.199829</td>\n",
       "      <td>-0.111267</td>\n",
       "      <td>0.022995</td>\n",
       "      <td>0.520508</td>\n",
       "      <td>0.013527</td>\n",
       "      <td>0.333008</td>\n",
       "      <td>0.644531</td>\n",
       "      <td>-0.185059</td>\n",
       "      <td>0.332031</td>\n",
       "      <td>...</td>\n",
       "      <td>0.267578</td>\n",
       "      <td>-0.140869</td>\n",
       "      <td>0.055328</td>\n",
       "      <td>0.227295</td>\n",
       "      <td>0.216309</td>\n",
       "      <td>0.521973</td>\n",
       "      <td>0.082581</td>\n",
       "      <td>0.078857</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.144287</td>\n",
       "      <td>0.273682</td>\n",
       "      <td>-0.015129</td>\n",
       "      <td>0.013245</td>\n",
       "      <td>-0.019623</td>\n",
       "      <td>0.052643</td>\n",
       "      <td>0.367676</td>\n",
       "      <td>0.298828</td>\n",
       "      <td>0.063599</td>\n",
       "      <td>-0.234131</td>\n",
       "      <td>...</td>\n",
       "      <td>0.181152</td>\n",
       "      <td>-0.333008</td>\n",
       "      <td>0.103577</td>\n",
       "      <td>0.120300</td>\n",
       "      <td>0.172729</td>\n",
       "      <td>0.808594</td>\n",
       "      <td>-0.005161</td>\n",
       "      <td>0.482422</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>0.384521</td>\n",
       "      <td>0.001780</td>\n",
       "      <td>0.010330</td>\n",
       "      <td>-0.373535</td>\n",
       "      <td>0.003527</td>\n",
       "      <td>-0.173828</td>\n",
       "      <td>0.265137</td>\n",
       "      <td>0.809570</td>\n",
       "      <td>-0.310791</td>\n",
       "      <td>0.321533</td>\n",
       "      <td>...</td>\n",
       "      <td>0.914551</td>\n",
       "      <td>-0.247437</td>\n",
       "      <td>0.102600</td>\n",
       "      <td>0.454102</td>\n",
       "      <td>0.049683</td>\n",
       "      <td>0.587891</td>\n",
       "      <td>0.343506</td>\n",
       "      <td>-0.193848</td>\n",
       "      <td>2</td>\n",
       "      <td>-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>0.326660</td>\n",
       "      <td>-0.057800</td>\n",
       "      <td>-0.433838</td>\n",
       "      <td>0.026611</td>\n",
       "      <td>0.405273</td>\n",
       "      <td>-0.307129</td>\n",
       "      <td>0.231445</td>\n",
       "      <td>0.496826</td>\n",
       "      <td>-0.186401</td>\n",
       "      <td>0.021179</td>\n",
       "      <td>...</td>\n",
       "      <td>0.181396</td>\n",
       "      <td>-0.292480</td>\n",
       "      <td>0.116516</td>\n",
       "      <td>0.266357</td>\n",
       "      <td>-0.109070</td>\n",
       "      <td>1.097656</td>\n",
       "      <td>0.289062</td>\n",
       "      <td>0.182129</td>\n",
       "      <td>6</td>\n",
       "      <td>-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>0.243896</td>\n",
       "      <td>0.031342</td>\n",
       "      <td>-0.212524</td>\n",
       "      <td>-0.059174</td>\n",
       "      <td>0.381104</td>\n",
       "      <td>0.453125</td>\n",
       "      <td>0.387207</td>\n",
       "      <td>0.718262</td>\n",
       "      <td>-0.110718</td>\n",
       "      <td>0.239990</td>\n",
       "      <td>...</td>\n",
       "      <td>0.281494</td>\n",
       "      <td>0.340820</td>\n",
       "      <td>0.271729</td>\n",
       "      <td>0.133545</td>\n",
       "      <td>-0.217529</td>\n",
       "      <td>0.532715</td>\n",
       "      <td>-0.012230</td>\n",
       "      <td>-0.019974</td>\n",
       "      <td>9</td>\n",
       "      <td>-5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.223755</td>\n",
       "      <td>-0.123230</td>\n",
       "      <td>-0.211792</td>\n",
       "      <td>-0.057159</td>\n",
       "      <td>0.066162</td>\n",
       "      <td>0.348145</td>\n",
       "      <td>0.208618</td>\n",
       "      <td>-0.187622</td>\n",
       "      <td>-0.088989</td>\n",
       "      <td>...</td>\n",
       "      <td>0.528809</td>\n",
       "      <td>0.020004</td>\n",
       "      <td>0.259521</td>\n",
       "      <td>0.089355</td>\n",
       "      <td>-0.134033</td>\n",
       "      <td>1.244141</td>\n",
       "      <td>0.298584</td>\n",
       "      <td>0.028275</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>0.047821</td>\n",
       "      <td>0.203003</td>\n",
       "      <td>-0.272461</td>\n",
       "      <td>0.181396</td>\n",
       "      <td>0.468018</td>\n",
       "      <td>-0.081421</td>\n",
       "      <td>0.358398</td>\n",
       "      <td>0.552734</td>\n",
       "      <td>0.261963</td>\n",
       "      <td>-0.092712</td>\n",
       "      <td>...</td>\n",
       "      <td>0.173706</td>\n",
       "      <td>-0.247437</td>\n",
       "      <td>0.064453</td>\n",
       "      <td>0.073853</td>\n",
       "      <td>0.348633</td>\n",
       "      <td>0.386230</td>\n",
       "      <td>0.007130</td>\n",
       "      <td>0.132324</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 514 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2         3         4         5         6  \\\n",
       "0     -0.182129  0.077271 -0.269043 -0.252197  0.340820 -0.206543 -0.022476   \n",
       "1      0.044434  0.054596 -0.123657 -0.042114  0.639648  0.252686  0.126221   \n",
       "2      0.311523 -0.060028 -0.326416  0.091553  0.375732 -0.092041  0.256348   \n",
       "3      0.075439 -0.199829 -0.111267  0.022995  0.520508  0.013527  0.333008   \n",
       "4      0.144287  0.273682 -0.015129  0.013245 -0.019623  0.052643  0.367676   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "49995  0.384521  0.001780  0.010330 -0.373535  0.003527 -0.173828  0.265137   \n",
       "49996  0.326660 -0.057800 -0.433838  0.026611  0.405273 -0.307129  0.231445   \n",
       "49997  0.243896  0.031342 -0.212524 -0.059174  0.381104  0.453125  0.387207   \n",
       "49998  0.312500  0.223755 -0.123230 -0.211792 -0.057159  0.066162  0.348145   \n",
       "49999  0.047821  0.203003 -0.272461  0.181396  0.468018 -0.081421  0.358398   \n",
       "\n",
       "              7         8         9  ...       504       505       506  \\\n",
       "0      0.421875 -0.105896  0.204956  ...  0.542969 -0.122986  0.279785   \n",
       "1      0.460693 -0.091492  0.153687  ... -0.056641 -0.043518  0.264893   \n",
       "2      0.528809 -0.168701  0.213379  ...  0.006985 -0.364014  0.167480   \n",
       "3      0.644531 -0.185059  0.332031  ...  0.267578 -0.140869  0.055328   \n",
       "4      0.298828  0.063599 -0.234131  ...  0.181152 -0.333008  0.103577   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "49995  0.809570 -0.310791  0.321533  ...  0.914551 -0.247437  0.102600   \n",
       "49996  0.496826 -0.186401  0.021179  ...  0.181396 -0.292480  0.116516   \n",
       "49997  0.718262 -0.110718  0.239990  ...  0.281494  0.340820  0.271729   \n",
       "49998  0.208618 -0.187622 -0.088989  ...  0.528809  0.020004  0.259521   \n",
       "49999  0.552734  0.261963 -0.092712  ...  0.173706 -0.247437  0.064453   \n",
       "\n",
       "            507       508       509       510       511  label  sum  \n",
       "0      0.118042  0.339600  1.103516 -0.180786 -0.273926      6    0  \n",
       "1      0.195557  0.008942  0.951172  0.101868  0.137817      9   15  \n",
       "2      0.406738  0.063354  0.594727 -0.133789  0.062927      9   -6  \n",
       "3      0.227295  0.216309  0.521973  0.082581  0.078857      4    2  \n",
       "4      0.120300  0.172729  0.808594 -0.005161  0.482422      1    0  \n",
       "...         ...       ...       ...       ...       ...    ...  ...  \n",
       "49995  0.454102  0.049683  0.587891  0.343506 -0.193848      2  -15  \n",
       "49996  0.266357 -0.109070  1.097656  0.289062  0.182129      6  -10  \n",
       "49997  0.133545 -0.217529  0.532715 -0.012230 -0.019974      9   -5  \n",
       "49998  0.089355 -0.134033  1.244141  0.298584  0.028275      1    0  \n",
       "49999  0.073853  0.348633  0.386230  0.007130  0.132324      1    4  \n",
       "\n",
       "[50000 rows x 514 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "437c452c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('20221130-train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe45caa7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "71e4fa54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df1 = pd.DataFrame(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "199d777e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████| 10000/10000 [00:00<00:00, 130073.68it/s]\n"
     ]
    }
   ],
   "source": [
    "val1 = []\n",
    "for i in tqdm(range(len(test_features))):\n",
    "    val1.append(int(np.sum(test_features[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6e94f3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['label'] = test_labels\n",
    "df1['sum'] = val1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "26e0c43c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "835fd109",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>504</th>\n",
       "      <th>505</th>\n",
       "      <th>506</th>\n",
       "      <th>507</th>\n",
       "      <th>508</th>\n",
       "      <th>509</th>\n",
       "      <th>510</th>\n",
       "      <th>511</th>\n",
       "      <th>label</th>\n",
       "      <th>sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.234375</td>\n",
       "      <td>0.049835</td>\n",
       "      <td>-0.447998</td>\n",
       "      <td>-0.366211</td>\n",
       "      <td>0.076965</td>\n",
       "      <td>-0.219971</td>\n",
       "      <td>0.087219</td>\n",
       "      <td>0.945801</td>\n",
       "      <td>-0.408447</td>\n",
       "      <td>0.227539</td>\n",
       "      <td>...</td>\n",
       "      <td>0.521484</td>\n",
       "      <td>0.003767</td>\n",
       "      <td>0.355469</td>\n",
       "      <td>0.115234</td>\n",
       "      <td>-0.122864</td>\n",
       "      <td>0.534668</td>\n",
       "      <td>0.031082</td>\n",
       "      <td>0.232300</td>\n",
       "      <td>3</td>\n",
       "      <td>-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.481201</td>\n",
       "      <td>-0.031555</td>\n",
       "      <td>-0.068237</td>\n",
       "      <td>0.057007</td>\n",
       "      <td>0.151367</td>\n",
       "      <td>0.004078</td>\n",
       "      <td>0.489746</td>\n",
       "      <td>0.491943</td>\n",
       "      <td>0.161865</td>\n",
       "      <td>-0.114319</td>\n",
       "      <td>...</td>\n",
       "      <td>0.099182</td>\n",
       "      <td>-0.289062</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.180420</td>\n",
       "      <td>0.270264</td>\n",
       "      <td>0.548828</td>\n",
       "      <td>-0.032654</td>\n",
       "      <td>-0.254150</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.143921</td>\n",
       "      <td>-0.001245</td>\n",
       "      <td>-0.244873</td>\n",
       "      <td>-0.132568</td>\n",
       "      <td>0.137695</td>\n",
       "      <td>0.089905</td>\n",
       "      <td>0.239380</td>\n",
       "      <td>0.753906</td>\n",
       "      <td>0.271240</td>\n",
       "      <td>0.041779</td>\n",
       "      <td>...</td>\n",
       "      <td>0.676758</td>\n",
       "      <td>0.124756</td>\n",
       "      <td>-0.083435</td>\n",
       "      <td>0.391113</td>\n",
       "      <td>0.112610</td>\n",
       "      <td>0.613770</td>\n",
       "      <td>0.012512</td>\n",
       "      <td>0.050690</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.363281</td>\n",
       "      <td>-0.215210</td>\n",
       "      <td>-0.086853</td>\n",
       "      <td>-0.565918</td>\n",
       "      <td>0.644043</td>\n",
       "      <td>-0.493164</td>\n",
       "      <td>0.090454</td>\n",
       "      <td>0.178345</td>\n",
       "      <td>-0.345947</td>\n",
       "      <td>0.257812</td>\n",
       "      <td>...</td>\n",
       "      <td>0.751465</td>\n",
       "      <td>-0.644043</td>\n",
       "      <td>0.096802</td>\n",
       "      <td>0.248657</td>\n",
       "      <td>0.049011</td>\n",
       "      <td>0.731934</td>\n",
       "      <td>-0.446045</td>\n",
       "      <td>-0.159790</td>\n",
       "      <td>0</td>\n",
       "      <td>-9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.024628</td>\n",
       "      <td>-0.201416</td>\n",
       "      <td>0.009354</td>\n",
       "      <td>-0.221313</td>\n",
       "      <td>-0.304443</td>\n",
       "      <td>0.156494</td>\n",
       "      <td>0.045044</td>\n",
       "      <td>0.273193</td>\n",
       "      <td>0.558594</td>\n",
       "      <td>0.360107</td>\n",
       "      <td>...</td>\n",
       "      <td>0.398438</td>\n",
       "      <td>-0.527344</td>\n",
       "      <td>0.247437</td>\n",
       "      <td>-0.036865</td>\n",
       "      <td>0.348633</td>\n",
       "      <td>0.628418</td>\n",
       "      <td>0.016861</td>\n",
       "      <td>-0.250244</td>\n",
       "      <td>6</td>\n",
       "      <td>-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>0.260986</td>\n",
       "      <td>0.012497</td>\n",
       "      <td>-0.256592</td>\n",
       "      <td>-0.437500</td>\n",
       "      <td>0.389160</td>\n",
       "      <td>-0.120605</td>\n",
       "      <td>0.325195</td>\n",
       "      <td>1.038086</td>\n",
       "      <td>-0.139893</td>\n",
       "      <td>0.066467</td>\n",
       "      <td>...</td>\n",
       "      <td>0.389893</td>\n",
       "      <td>-0.068420</td>\n",
       "      <td>0.320068</td>\n",
       "      <td>0.111633</td>\n",
       "      <td>0.011375</td>\n",
       "      <td>0.780762</td>\n",
       "      <td>-0.031891</td>\n",
       "      <td>0.270264</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>0.180542</td>\n",
       "      <td>0.098511</td>\n",
       "      <td>-0.240723</td>\n",
       "      <td>0.151611</td>\n",
       "      <td>0.093933</td>\n",
       "      <td>-0.527832</td>\n",
       "      <td>0.167969</td>\n",
       "      <td>0.541016</td>\n",
       "      <td>0.087219</td>\n",
       "      <td>0.015373</td>\n",
       "      <td>...</td>\n",
       "      <td>0.459961</td>\n",
       "      <td>0.112549</td>\n",
       "      <td>0.020508</td>\n",
       "      <td>0.362305</td>\n",
       "      <td>-0.195801</td>\n",
       "      <td>0.966797</td>\n",
       "      <td>-0.016418</td>\n",
       "      <td>0.047699</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>0.005203</td>\n",
       "      <td>-0.169312</td>\n",
       "      <td>-0.412354</td>\n",
       "      <td>0.220215</td>\n",
       "      <td>0.468018</td>\n",
       "      <td>-0.075745</td>\n",
       "      <td>0.370117</td>\n",
       "      <td>0.578125</td>\n",
       "      <td>0.444336</td>\n",
       "      <td>0.109009</td>\n",
       "      <td>...</td>\n",
       "      <td>0.134277</td>\n",
       "      <td>0.187622</td>\n",
       "      <td>-0.135010</td>\n",
       "      <td>0.439453</td>\n",
       "      <td>-0.377197</td>\n",
       "      <td>0.774414</td>\n",
       "      <td>0.236328</td>\n",
       "      <td>0.064209</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>0.500977</td>\n",
       "      <td>0.154541</td>\n",
       "      <td>-0.029984</td>\n",
       "      <td>-0.383789</td>\n",
       "      <td>0.081177</td>\n",
       "      <td>0.244507</td>\n",
       "      <td>0.395020</td>\n",
       "      <td>0.761230</td>\n",
       "      <td>-0.185425</td>\n",
       "      <td>0.252930</td>\n",
       "      <td>...</td>\n",
       "      <td>0.337158</td>\n",
       "      <td>-0.393799</td>\n",
       "      <td>0.098633</td>\n",
       "      <td>-0.054413</td>\n",
       "      <td>0.252930</td>\n",
       "      <td>0.390869</td>\n",
       "      <td>-0.014481</td>\n",
       "      <td>-0.016296</td>\n",
       "      <td>1</td>\n",
       "      <td>-5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>0.156006</td>\n",
       "      <td>0.012787</td>\n",
       "      <td>-0.039001</td>\n",
       "      <td>0.073181</td>\n",
       "      <td>0.220825</td>\n",
       "      <td>-0.599121</td>\n",
       "      <td>0.783691</td>\n",
       "      <td>0.378662</td>\n",
       "      <td>0.357178</td>\n",
       "      <td>0.221191</td>\n",
       "      <td>...</td>\n",
       "      <td>0.275391</td>\n",
       "      <td>0.066467</td>\n",
       "      <td>0.129028</td>\n",
       "      <td>0.765625</td>\n",
       "      <td>0.058472</td>\n",
       "      <td>0.590820</td>\n",
       "      <td>0.126221</td>\n",
       "      <td>0.156982</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 514 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5         6  \\\n",
       "0     0.234375  0.049835 -0.447998 -0.366211  0.076965 -0.219971  0.087219   \n",
       "1     0.481201 -0.031555 -0.068237  0.057007  0.151367  0.004078  0.489746   \n",
       "2     0.143921 -0.001245 -0.244873 -0.132568  0.137695  0.089905  0.239380   \n",
       "3     0.363281 -0.215210 -0.086853 -0.565918  0.644043 -0.493164  0.090454   \n",
       "4    -0.024628 -0.201416  0.009354 -0.221313 -0.304443  0.156494  0.045044   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "9995  0.260986  0.012497 -0.256592 -0.437500  0.389160 -0.120605  0.325195   \n",
       "9996  0.180542  0.098511 -0.240723  0.151611  0.093933 -0.527832  0.167969   \n",
       "9997  0.005203 -0.169312 -0.412354  0.220215  0.468018 -0.075745  0.370117   \n",
       "9998  0.500977  0.154541 -0.029984 -0.383789  0.081177  0.244507  0.395020   \n",
       "9999  0.156006  0.012787 -0.039001  0.073181  0.220825 -0.599121  0.783691   \n",
       "\n",
       "             7         8         9  ...       504       505       506  \\\n",
       "0     0.945801 -0.408447  0.227539  ...  0.521484  0.003767  0.355469   \n",
       "1     0.491943  0.161865 -0.114319  ...  0.099182 -0.289062  0.007778   \n",
       "2     0.753906  0.271240  0.041779  ...  0.676758  0.124756 -0.083435   \n",
       "3     0.178345 -0.345947  0.257812  ...  0.751465 -0.644043  0.096802   \n",
       "4     0.273193  0.558594  0.360107  ...  0.398438 -0.527344  0.247437   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "9995  1.038086 -0.139893  0.066467  ...  0.389893 -0.068420  0.320068   \n",
       "9996  0.541016  0.087219  0.015373  ...  0.459961  0.112549  0.020508   \n",
       "9997  0.578125  0.444336  0.109009  ...  0.134277  0.187622 -0.135010   \n",
       "9998  0.761230 -0.185425  0.252930  ...  0.337158 -0.393799  0.098633   \n",
       "9999  0.378662  0.357178  0.221191  ...  0.275391  0.066467  0.129028   \n",
       "\n",
       "           507       508       509       510       511  label  sum  \n",
       "0     0.115234 -0.122864  0.534668  0.031082  0.232300      3   -3  \n",
       "1     0.180420  0.270264  0.548828 -0.032654 -0.254150      8    3  \n",
       "2     0.391113  0.112610  0.613770  0.012512  0.050690      8    0  \n",
       "3     0.248657  0.049011  0.731934 -0.446045 -0.159790      0   -9  \n",
       "4    -0.036865  0.348633  0.628418  0.016861 -0.250244      6  -17  \n",
       "...        ...       ...       ...       ...       ...    ...  ...  \n",
       "9995  0.111633  0.011375  0.780762 -0.031891  0.270264      8    1  \n",
       "9996  0.362305 -0.195801  0.966797 -0.016418  0.047699      3   -1  \n",
       "9997  0.439453 -0.377197  0.774414  0.236328  0.064209      5    0  \n",
       "9998 -0.054413  0.252930  0.390869 -0.014481 -0.016296      1   -5  \n",
       "9999  0.765625  0.058472  0.590820  0.126221  0.156982      7    2  \n",
       "\n",
       "[10000 rows x 514 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "026aa998",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_csv('20221130-test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11f5761",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4889e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_0 = []\n",
    "for i in range(len(train_labels)):\n",
    "    if train_labels[i] == 0:\n",
    "        train_0.append(train_features[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "16edeb7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_1 = []\n",
    "for i in range(len(train_labels)):\n",
    "    if train_labels[i] == 1:\n",
    "        train_1.append(train_features[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "65dd249d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_2 = []\n",
    "for i in range(len(train_labels)):\n",
    "    if train_labels[i] == 2:\n",
    "        train_2.append(train_features[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "99327f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_3 = []\n",
    "for i in range(len(train_labels)):\n",
    "    if train_labels[i] == 3:\n",
    "        train_3.append(train_features[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c503000b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_4 = []\n",
    "for i in range(len(train_labels)):\n",
    "    if train_labels[i] == 4:\n",
    "        train_4.append(train_features[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "95cfc773",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_5 = []\n",
    "for i in range(len(train_labels)):\n",
    "    if train_labels[i] == 5:\n",
    "        train_5.append(train_features[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "556b3917",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_6 = []\n",
    "for i in range(len(train_labels)):\n",
    "    if train_labels[i] == 6:\n",
    "        train_6.append(train_features[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c34f2285",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_7 = []\n",
    "for i in range(len(train_labels)):\n",
    "    if train_labels[i] == 7:\n",
    "        train_7.append(train_features[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "19e9a19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_8 = []\n",
    "for i in range(len(train_labels)):\n",
    "    if train_labels[i] == 8:\n",
    "        train_8.append(train_features[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6f17dee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_9 = []\n",
    "for i in range(len(train_labels)):\n",
    "    if train_labels[i] == 9:\n",
    "        train_9.append(train_features[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "58cda4d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "829a43ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(a, b):\n",
    "    a_norm = np.linalg.norm(a)\n",
    "    b_norm = np.linalg.norm(b)\n",
    "    a_b_dot = np.inner(a, b)\n",
    "    return np.mean(a_b_dot / (a_norm * b_norm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b4577698",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_norm(a, b):\n",
    "    new = a - b\n",
    "    val = np.square(new)\n",
    "    return np.mean(np.sqrt(val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0e1b8689",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 5000/5000 [25:27<00:00,  3.27it/s]\n"
     ]
    }
   ],
   "source": [
    "train_0_score = []\n",
    "for i in tqdm(range(len(train_0))):\n",
    "    temp = []\n",
    "    for j in range(len(train_0)):\n",
    "        temp.append(cosine_similarity(train_0[i], train_0[j]) + f_norm(train_0[i], train_0[j]))\n",
    "    train_0_score.append(np.mean(temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2807d3d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 5000/5000 [25:26<00:00,  3.28it/s]\n"
     ]
    }
   ],
   "source": [
    "train_1_score = []\n",
    "for i in tqdm(range(len(train_1))):\n",
    "    temp = []\n",
    "    for j in range(len(train_1)):\n",
    "        temp.append(cosine_similarity(train_1[i], train_1[j]) + f_norm(train_1[i], train_1[j]))\n",
    "    train_1_score.append(np.mean(temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7c5edf41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 5000/5000 [25:24<00:00,  3.28it/s]\n"
     ]
    }
   ],
   "source": [
    "train_2_score = []\n",
    "for i in tqdm(range(len(train_2))):\n",
    "    temp = []\n",
    "    for j in range(len(train_2)):\n",
    "        temp.append(cosine_similarity(train_2[i], train_2[j]) + f_norm(train_2[i], train_2[j]))\n",
    "    train_2_score.append(np.mean(temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "176608bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 5000/5000 [25:25<00:00,  3.28it/s]\n"
     ]
    }
   ],
   "source": [
    "train_3_score = []\n",
    "for i in tqdm(range(len(train_3))):\n",
    "    temp = []\n",
    "    for j in range(len(train_3)):\n",
    "        temp.append(cosine_similarity(train_3[i], train_3[j]) + f_norm(train_3[i], train_3[j]))\n",
    "    train_3_score.append(np.mean(temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "94088213",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 5000/5000 [25:10<00:00,  3.31it/s]\n"
     ]
    }
   ],
   "source": [
    "train_4_score = []\n",
    "for i in tqdm(range(len(train_4))):\n",
    "    temp = []\n",
    "    for j in range(len(train_4)):\n",
    "        temp.append(cosine_similarity(train_4[i], train_4[j]) + f_norm(train_4[i], train_4[j]))\n",
    "    train_4_score.append(np.mean(temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bd6f55db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 5000/5000 [25:03<00:00,  3.32it/s]\n"
     ]
    }
   ],
   "source": [
    "train_5_score = []\n",
    "for i in tqdm(range(len(train_5))):\n",
    "    temp = []\n",
    "    for j in range(len(train_5)):\n",
    "        temp.append(cosine_similarity(train_5[i], train_5[j]) + f_norm(train_5[i], train_5[j]))\n",
    "    train_5_score.append(np.mean(temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e2976f61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 5000/5000 [25:19<00:00,  3.29it/s]\n"
     ]
    }
   ],
   "source": [
    "train_6_score = []\n",
    "for i in tqdm(range(len(train_6))):\n",
    "    temp = []\n",
    "    for j in range(len(train_6)):\n",
    "        temp.append(cosine_similarity(train_6[i], train_6[j]) + f_norm(train_6[i], train_6[j]))\n",
    "    train_6_score.append(np.mean(temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "645868b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 5000/5000 [25:29<00:00,  3.27it/s]\n"
     ]
    }
   ],
   "source": [
    "train_7_score = []\n",
    "for i in tqdm(range(len(train_7))):\n",
    "    temp = []\n",
    "    for j in range(len(train_7)):\n",
    "        temp.append(cosine_similarity(train_7[i], train_7[j]) + f_norm(train_7[i], train_7[j]))\n",
    "    train_7_score.append(np.mean(temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6803e2d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 5000/5000 [25:25<00:00,  3.28it/s]\n"
     ]
    }
   ],
   "source": [
    "train_8_score = []\n",
    "for i in tqdm(range(len(train_8))):\n",
    "    temp = []\n",
    "    for j in range(len(train_8)):\n",
    "        temp.append(cosine_similarity(train_8[i], train_8[j]) + f_norm(train_8[i], train_8[j]))\n",
    "    train_8_score.append(np.mean(temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7b045c48",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 5000/5000 [25:37<00:00,  3.25it/s]\n"
     ]
    }
   ],
   "source": [
    "train_9_score = []\n",
    "for i in tqdm(range(len(train_9))):\n",
    "    temp = []\n",
    "    for j in range(len(train_9)):\n",
    "        temp.append(cosine_similarity(train_9[i], train_9[j]) + f_norm(train_9[i], train_9[j]))\n",
    "    train_9_score.append(np.mean(temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2650523d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 5000/5000 [00:00<00:00, 158943.79it/s]\n"
     ]
    }
   ],
   "source": [
    "train_0_val = []\n",
    "for i in tqdm(range(len(train_0))):\n",
    "    train_0_val.append(np.sum(train_0[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "336bff16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 5000/5000 [00:00<00:00, 155793.51it/s]\n"
     ]
    }
   ],
   "source": [
    "train_1_val = []\n",
    "for i in tqdm(range(len(train_1))):\n",
    "    train_1_val.append(np.sum(train_1[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ac96ac72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 5000/5000 [00:00<00:00, 172882.57it/s]\n"
     ]
    }
   ],
   "source": [
    "train_2_val = []\n",
    "for i in tqdm(range(len(train_2))):\n",
    "    train_2_val.append(np.sum(train_2[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e0ed122c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 5000/5000 [00:00<00:00, 178067.30it/s]\n"
     ]
    }
   ],
   "source": [
    "train_3_val = []\n",
    "for i in tqdm(range(len(train_3))):\n",
    "    train_3_val.append(np.sum(train_3[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2f9fb645",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 5000/5000 [00:00<00:00, 183707.70it/s]\n"
     ]
    }
   ],
   "source": [
    "train_4_val = []\n",
    "for i in tqdm(range(len(train_4))):\n",
    "    train_4_val.append(np.sum(train_4[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "12beebf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 5000/5000 [00:00<00:00, 195327.38it/s]\n"
     ]
    }
   ],
   "source": [
    "train_5_val = []\n",
    "for i in tqdm(range(len(train_5))):\n",
    "    train_5_val.append(np.sum(train_5[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ebd12326",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 5000/5000 [00:00<00:00, 177145.27it/s]\n"
     ]
    }
   ],
   "source": [
    "train_6_val = []\n",
    "for i in tqdm(range(len(train_6))):\n",
    "    train_6_val.append(np.sum(train_6[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "119be61f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 5000/5000 [00:00<00:00, 175654.11it/s]\n"
     ]
    }
   ],
   "source": [
    "train_7_val = []\n",
    "for i in tqdm(range(len(train_7))):\n",
    "    train_7_val.append(np.sum(train_7[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "82c6c3a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 5000/5000 [00:00<00:00, 181518.17it/s]\n"
     ]
    }
   ],
   "source": [
    "train_8_val = []\n",
    "for i in tqdm(range(len(train_8))):\n",
    "    train_8_val.append(np.sum(train_8[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9158f7f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 5000/5000 [00:00<00:00, 185357.39it/s]\n"
     ]
    }
   ],
   "source": [
    "train_9_val = []\n",
    "for i in tqdm(range(len(train_9))):\n",
    "    train_9_val.append(np.sum(train_9[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968bae33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a2d41f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
